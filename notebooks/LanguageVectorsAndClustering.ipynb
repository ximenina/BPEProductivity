{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "average-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os\n",
    "import sys\n",
    "from re import sub\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from random import sample\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 6]\n",
    "from pandas import DataFrame\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adjacent-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=\"../outputs/BPEresults_productivity_corpusPBCtok_0_200_1/tsv/\"  #tsv directory \n",
    "output=\"../outputs/BPEresults_productivity_corpusPBCtok_0_200_1/corpusPBCtok200_vectors.csv\"                  #for storing the resulting centered and scaled datapoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-selling",
   "metadata": {},
   "source": [
    "# BPE SPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "simple-china",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e8224c97474f9488635673cf46511d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_files = os.listdir(directory)\n",
    "\n",
    "df_avg = pd.DataFrame(columns = ['file', 'prod', 'cum_freq', 'idiosincracy_index'])\n",
    "\n",
    "for n in all_files:\n",
    "\tinputcorpus=directory+n\n",
    "\tdata = pd.read_csv(inputcorpus,  sep='\\t')\n",
    "\t#print (\"Processing\"+n)\n",
    "\n",
    "\tfileparts=n.split(\".\")\n",
    "\tisocode=fileparts[0].split(\"-\")\n",
    "\n",
    "\tx = data['prod'].mean()\n",
    "\ty = data['cum_freq'].mean()\n",
    "\tz = data['idiosincracy_index'].mean()\n",
    "\n",
    "\tdf_aux = pd.DataFrame([[isocode[0], x,y,z]], columns=['file', 'prod', 'cum_freq', 'idiosincracy_index'])\n",
    "\tdf_avg=df_avg.append(df_aux)\n",
    "\n",
    "#print(df_avg.describe())\n",
    "df_isocodes=df_avg.iloc[:, 0:1] \n",
    "df_isocodes=df_isocodes.reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_avg.columns = range(df_avg.shape[1]) #remove header\n",
    "df_avg = df_avg.iloc[: , 1:]  #remove first column\n",
    "\n",
    "# perform a robust scaler transform of the dataset\n",
    "trans = StandardScaler()\n",
    "data = trans.fit_transform(df_avg)\n",
    "# convert the array back to a dataframe\n",
    "df_data= DataFrame(data)\n",
    "df_avg_transformed=df_isocodes.join(df_data)\n",
    "df_avg_transformed.rename(columns={0:'prod',\n",
    "                          1:'cum_freq',\n",
    "                          2:'idiosincracy_index'}, \n",
    "                 inplace=True)\n",
    "\n",
    "\n",
    "  \n",
    "df_avg_transformed.to_csv(output, index=False,)\n",
    "\n",
    "fig = plt.figure(figsize=(13.6, 13.6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "xs = df_avg_transformed['prod']\n",
    "ys = df_avg_transformed['cum_freq']\n",
    "zs = df_avg_transformed['idiosincracy_index']\n",
    "labels=df_avg_transformed['file']\n",
    "\n",
    "ax.set_xlabel('|W| Productivity',fontdict=dict(weight='bold'))\n",
    "ax.set_ylabel('C. freq',fontdict=dict(weight='bold'))\n",
    "ax.set_zlabel('Idiosyncrasy',fontdict=dict(weight='bold'))\n",
    "#ax.set_xlim(-3, 3)\n",
    "#ax.set_ylim(-2.5, 2.5)\n",
    "#ax.set_zlim(-3,3)\n",
    "#plt.zlim([-3, 3])\n",
    "img=ax.scatter(xs, ys, zs, c=xs, s=50, alpha=1, edgecolors='w', cmap=\"jet\")# cmap='jet')\n",
    "\n",
    "#for x, y, z, label in zip(xs, ys, zs, labels):\n",
    "#    ax.text(x, y, z, label,weight=\"book\", size=\"large\")\n",
    "\n",
    "######FIX for text colors:\n",
    "colors=xs.tolist()\n",
    "for x, y, z, label, color in zip(xs, ys, zs, labels, colors):\n",
    "    if (color<=-1):\n",
    "        ax.text(x, y, z, label,weight=\"book\", size=\"large\", color=\"#00009b\", fontweight=\"medium\")\n",
    "    if (color>-1 and color<-0.4):\n",
    "        ax.text(x, y, z, label,weight=\"book\", size=\"large\",  color=\"#0000cd\", fontweight=\"medium\")       \n",
    "    if (color>=-0.4 and color<0):\n",
    "        ax.text(x, y, z, label,weight=\"book\", size=\"large\",  color=\"#007dff\", fontweight=\"medium\")\n",
    "    if (color>=0 and color<0.2):\n",
    "        ax.text(x, y, z, label,weight=\"book\", size=\"large\",  color=\"#00b9ff\", fontweight=\"medium\")#, backgroundcolor=\"white\", alpha=0.1)\n",
    "    if (color>=0.2 and color<0.4):\n",
    "        ax.text(x, y, z, label,weight=\"book\", size=\"large\",  color=\"#02e8f4\", fontweight=\"medium\")#, backgroundcolor=\"white\", alpha=0.1)\n",
    "    if (color>=0.4 and color<0.6):\n",
    "        ax.text(x, y, z, label,weight=\"book\", size=\"large\",  color=\"#23ffd4\", fontweight=\"medium\")#, backgroundcolor=\"white\", alpha=0.1)  \n",
    "    if (color>=0.6 and color<1.1):\n",
    "        ax.text(x, y, z, label,weight=\"book\", size=\"large\",  color=\"#5fffaa\", fontweight=\"medium\")#, backgroundcolor=\"white\", alpha=0.1)\n",
    "        \n",
    "    if (color>=1.1 and color<2):\n",
    "        ax.text(x, y, z, label,weight=\"book\", size=\"large\",  color=\"#baff3c\", fontweight=\"medium\")#, backgroundcolor=\"white\", alpha=0.1)\n",
    "        \n",
    "    if (color>=2 and color<3):\n",
    "        ax.text(x, y, z, label,weight=\"book\", size=\"large\",  color=\"#ff4300\", fontweight=\"medium\")#, backgroundcolor=\"white\", alpha=0.1)\n",
    "        \n",
    "    if (color>3):\n",
    "        ax.text(x, y, z, label,weight=\"book\", size=\"large\",  color=\"#800000\", fontweight=\"medium\")#, backgroundcolor=\"white\", alpha=0.1)\n",
    "        \n",
    "            \n",
    "#fig.colorbar(img)\n",
    "cbar=plt.colorbar(img, fraction=0.026, pad=0.04)\n",
    "plt.savefig(\"../outputs/BPEresults_productivity_corpusPBCtok_0_200_1/BPE_space.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-tyler",
   "metadata": {},
   "source": [
    "# WALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "worthy-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "wals_lang=pd.read_csv('WALS/languages.csv',index_col=1)\n",
    "wals_values=pd.read_csv('WALS/values.csv',index_col=0)\n",
    "\n",
    "bpe_vectors=pd.read_csv(output,index_col=0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "charged-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We obtain the isocodes and extract from wals info only for those languages ( they are part of the Samples_100)\n",
    "isocodes=bpe_vectors.index.tolist()\n",
    "wals_lang_filtered=wals_lang.query('ISO_codes in @isocodes')\n",
    "wals_lang_filtered=wals_lang_filtered.loc[wals_lang_filtered['Samples_100'] == True]\n",
    "wals_lang_filtered=wals_lang_filtered.drop(['Samples_100','Samples_200'], 1)\n",
    "#wals_lang_filtered.to_csv(\"extended_info.csv\", index=False,)\n",
    "wals_lang_filtered\n",
    "#Kew and Jac missing, original csv  had to be modified\n",
    "\n",
    "featuresofinterest=[\"20A\", \"22A\", \"26A\", \"27A\", \"28A\", \"29A\", \"30A\", \"33A\", \"34A\", \"37A\", \"38A\", \"49A\", \"51A\", \"57A\", \"59A\", \"65A\", \"66A\", \"67A\", \"69A\", \"70A\", \"73A\", \"74A\", \"75A\", \"78A\", \"94A\", \"101A\", \"102A\", \"111A\", \"112A\"]\n",
    "walscodes=wals_lang_filtered[\"ID\"].tolist()\n",
    "\n",
    "all_features=bpe_vectors\n",
    "for feature in featuresofinterest:\n",
    "\n",
    "    \n",
    "    wals_values_filtered=wals_values.query('Language_ID in @walscodes')\n",
    "    wals_values_filtered=wals_values_filtered.loc[wals_values_filtered['Parameter_ID'] == feature]\n",
    "    wals_values_filtered\n",
    "    #renaming and merging:\n",
    "    wals_lang_filtered=wals_lang_filtered.rename(columns={\"ID\": \"Language_ID\"})\n",
    "    wals_lang_filtered\n",
    "\n",
    "    aux1=wals_values_filtered.merge(wals_lang_filtered, on=\"Language_ID\")\n",
    "    aux1=aux1.drop(['Comment','Source_x','Example_ID','Source_y',], 1)\n",
    "    aux1=aux1.rename(columns={\"ISO_codes\": \"file\"})\n",
    "    aux1=aux1.set_index('file')\n",
    "    aux1\n",
    "\n",
    "    all_values=bpe_vectors.join(aux1) #What we need for each feature\n",
    "    \n",
    "    all_features=all_features.join(aux1['Value'])\n",
    "    all_features=all_features.rename(columns={\"Value\": feature}) #all features together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "general-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_features=all_features[[\"20A\", \"49A\", \"69A\", \"70A\", \"112A\", \"22A\", \"26A\", \"28A\", \"29A\", \"59A\", \"65A\", \"66A\", \"67A\", \"78A\", \"102A\"]]  #Adding 20A\n",
    "#substitute nan by zero:\n",
    "some_features=some_features.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-group",
   "metadata": {},
   "source": [
    "CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "absolute-banking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e909359f6e04a6bad035e87b9a94e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11819002209656738\n"
     ]
    }
   ],
   "source": [
    "caption=\"normal\"\n",
    "dataset=some_features\n",
    "clusters=4\n",
    "#Center and scaling:\n",
    "trans = StandardScaler()\n",
    "data = trans.fit_transform(dataset)\n",
    "##################Kclustering:#######################################3\n",
    "#km = sklearn.cluster.KMeans(n_clusters=clusters, init='k-means++', algorithm=\"full\")\n",
    "km = sklearn.cluster.KMeans(n_clusters=clusters, random_state=173, init='k-means++', algorithm=\"full\")  #299\n",
    "#km=sklearn.cluster.AgglomerativeClustering(n_clusters=clusters)\n",
    "#km=sklearn.cluster.SpectralClustering(n_clusters=clusters, assign_labels='discretize', random_state=0)\n",
    "#km = sklearn.cluster.AffinityPropagation(preference=-50, random_state=0)\n",
    "km.fit(data)\n",
    "\n",
    "# Get cluster assignment labels\n",
    "labels = km.labels_\n",
    "# Format results as a DataFrame\n",
    "results = pd.DataFrame([dataset.index,labels]).T  \n",
    "\n",
    "#Join the clustering with the info for each language\n",
    "#clustered=pd.concat([dataset, results],  axis=1)\n",
    "\n",
    "results=results.rename(columns={1: \"cluster\", 0:\"file\"})\n",
    "results=results.set_index(\"file\")\n",
    "#results.to_csv(\"features\"+caption+\"clustering_k\"+str(clusters)+\".csv\", index=True,)\n",
    "\n",
    "######################Plotting:###############################################################\n",
    "import matplotlib.colors\n",
    "\n",
    "colors_custom=[ \"#8000FF\",\"aqua\",\"#FDD835\",\"green\"]\n",
    "\n",
    "cmap= matplotlib.colors.ListedColormap(colors_custom)\n",
    "cmap.set_under(\"crimson\")\n",
    "cmap.set_over(\"w\")\n",
    "\n",
    "colors=results[\"cluster\"].tolist() #converting nan to zeros\n",
    "labels=results.index.tolist() #languages\n",
    "\n",
    "fig = plt.figure(figsize=(13, 13))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "xs = all_values['prod']\n",
    "ys = all_values['cum_freq']\n",
    "zs = all_values['idiosincracy_index']\n",
    "\n",
    "\n",
    "ax.set_xlabel('|W| Productivity',fontdict=dict(weight='bold'))\n",
    "ax.set_ylabel('C. freq',fontdict=dict(weight='bold'))\n",
    "ax.set_zlabel('Idiosyncrasy',fontdict=dict(weight='bold'))\n",
    "\n",
    "img=ax.scatter(xs, ys, zs, s=50, alpha=0.6, edgecolors='w', c=colors,cmap=cmap)  #cmap gist_rainbow\"\n",
    "ax.set_title(\"Clustering WALS based \"+ caption)\n",
    "for x, y, z, label, color in zip(xs, ys, zs, labels, colors):\n",
    "    if (color==0):\n",
    "        ax.text(x, y, z, label,weight=\"book\", size=\"large\", color=\"#8000FF\", fontweight=\"medium\")\n",
    "    if (color==1):\n",
    "        ax.text(x, y, z, label,weight=\"book\", size=\"large\",  color=\"aqua\", fontweight=\"medium\")       \n",
    "    if (color==2):\n",
    "        ax.text(x, y, z, label,weight=\"book\", size=\"large\",  color=\"#FDD835\", fontweight=\"medium\")\n",
    "    if (color==3):\n",
    "        ax.text(x, y, z, label,weight=\"book\", size=\"large\",  color=\"green\", fontweight=\"medium\")#, backgroundcolor=\"white\", alpha=0.1)\n",
    "cbar=fig.colorbar(img, fraction=0.026, pad=0.04, ticks=np.linspace(0,clusters-1,clusters))  #discrete colorbar\n",
    "tick_font_size = 15\n",
    "#cbar.ax.tick_params(labelsize=tick_font_size)\n",
    "\n",
    "\n",
    "plt.savefig(\"../outputs/BPEresults_productivity_corpusPBCtok_0_200_1/WALSClustering.png\")\n",
    "\n",
    "\n",
    "####Silhouette score\n",
    "X = all_values[['prod', 'cum_freq', 'idiosincracy_index']]\n",
    "S=metrics.silhouette_score(X, km.labels_, metric=\"sqeuclidean\")   #braycurtis\n",
    "#S=metrics.silhouette_score(data, km.labels_, metric=\"sqeuclidean\")   #braycurtis\n",
    "print(S)\n",
    "\n",
    "#[‘braycurtis’, ‘canberra’, ‘chebyshev’, ‘correlation’, ‘dice’, ‘hamming’, ‘jaccard’, ‘kulsinski’, ‘mahalanobis’, ‘minkowski’, ‘rogerstanimoto’, ‘russellrao’, ‘seuclidean’, ‘sokalmichener’, ‘sokalsneath’, ‘sqeuclidean’, ‘yule’] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-local",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-gasoline",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
